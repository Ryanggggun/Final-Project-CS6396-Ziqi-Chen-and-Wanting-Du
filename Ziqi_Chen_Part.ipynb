{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic\n",
    "from joblib import dump\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# train test split\n",
    "X = df['content_cleaned']\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# use TF-IDF performing feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "# model fit\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "dump(clf, 'logistic_regression_model.joblib')\n",
    "dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "# prediction\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "# results\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "accuracy, classification_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "# load BERT and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "# data preprocessing\n",
    "sub_df = df.head(100000)\n",
    "inputs = tokenizer.batch_encode_plus(list(sub_df['content_cleaned']), truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_masks = inputs[\"attention_mask\"]\n",
    "labels = torch.tensor(sub_df['sentiment'].values)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "input_ids = input_ids.to(device)\n",
    "attention_masks = attention_masks.to(device)\n",
    "labels = labels.to(device)\n",
    "# construct PyTorch datatset\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "# split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "# fine tune\n",
    "from tqdm import tqdm\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(3):  # 3 rounds\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        input_ids, attention_masks, labels = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "# evaluation\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "for batch in val_loader:\n",
    "    input_ids, attention_masks, labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "accuracy = (torch.tensor(all_preds) == torch.tensor(all_labels)).float().mean()\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Convert the list of tensors to a single tensor and then move it to CPU\n",
    "all_preds_tensor = torch.stack(all_preds).cpu()\n",
    "all_labels_tensor = torch.stack(all_labels).cpu()\n",
    "\n",
    "# Now convert to NumPy arrays\n",
    "all_preds_array = all_preds_tensor.numpy()\n",
    "all_labels_array = all_labels_tensor.numpy()\n",
    "\n",
    "# Calculate the confusion matrix using scikit-learn\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels_array, all_preds_array, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatgpt's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'  \n",
    "\n",
    "def get_chatgpt_response(comment, product_url, model=\"gpt-4-1106-preview\", max_tokens=60):\n",
    "    prompt = f\"A customer has a concern about the product: '{comment}'. Imagine that you are a competitor of that product and sell the benefits of your own product based on the claim. Don't include sorry and thank you's. Answer in a positive sunny way! don't apologize, and present the benefits of the product(For example, it's cost-effective, very good quality and looks great. Respond to reviews based on their claims). End the response with a link to the product website for additional support.\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        reply = response['choices'][0]['message']['content'].strip()\n",
    "        return f\"{reply}\\nFor more information, please visit our website: {product_url}\"\n",
    "    except openai.error.OpenAIError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\" \n",
    "\n",
    "product_url_example = \"http://www.example.com\"\n",
    "n_df = df[df['sentiment'] == 0]\n",
    "sub_df = n_df.iloc[0:1000]\n",
    "responses = []\n",
    "for comment in sub_df['content']: \n",
    "    response = get_chatgpt_response(comment, product_url_example)\n",
    "    responses.append(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=['Comment', 'Response'],\n",
    "                line_color='darkslategray',\n",
    "                fill_color='lightskyblue',\n",
    "                align='center'),\n",
    "    cells=dict(values=[sub_df['content'], responses],\n",
    "               line_color='darkslategray',\n",
    "               fill_color='lightcyan',\n",
    "               align='left',\n",
    "               font_size=12,\n",
    "               height=30))\n",
    "])\n",
    "\n",
    "\n",
    "fig.update_layout(width=700, height=400, title_text=\"Interactive Comments and Responses Table\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from joblib import load\n",
    "\n",
    "# Load the saved logistic regression model and TF-IDF vectorizer\n",
    "clf = load('logistic_regression_model.joblib')\n",
    "tfidf_vectorizer = load('tfidf_vectorizer.joblib')\n",
    "\n",
    "# Function to calculate sentiment score\n",
    "def get_sentiment_score(text):\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "    return clf.predict(text_tfidf)[0]\n",
    "\n",
    "\n",
    "# Calculate sentiment scores\n",
    "sentiment_scores = []\n",
    "\n",
    "\n",
    "for response in responses:\n",
    "    sentiment_scores.append(get_sentiment_score(response))\n",
    "\n",
    "\n",
    "# Calculate the averages\n",
    "average_sentiment_score = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0\n",
    "\n",
    "\n",
    "# Print or store the average scores\n",
    "print(\"Average Sentiment Score:\", average_sentiment_score)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
